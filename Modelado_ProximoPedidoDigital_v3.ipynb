{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0007db02",
   "metadata": {},
   "source": [
    "# Modelado — Próximo pedido **DIGITAL** (v3, 100% PySpark + Backtesting & Ensembles)\n",
    "\n",
    "**Objetivo:** predecir si el **próximo pedido** de un cliente será **DIGITAL**.\n",
    "\n",
    "**Mejoras sobre v2:**\n",
    "\n",
    "- Etiqueta *determinista* por cliente-mes.\n",
    "\n",
    "- **Features avanzadas** (rolling 3m, crecimiento, ciclo de vida del cliente).\n",
    "\n",
    "- **Priorización temporal**: split por fecha y opción de **backtesting**.\n",
    "\n",
    "- **Modelos**: Regresión Logística, **Random Forest**, **GBT** (boosting).\n",
    "\n",
    "- **Búsqueda de hiperparámetros** y **balanceo por clase**.\n",
    "\n",
    "- **Tuning de umbral**, **métricas por segmento** y **calibración** de prob.\n",
    "\n",
    "- Exportación de **artefactos** y **métricas** para el repo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961550a",
   "metadata": {},
   "source": [
    "## 1) Sesión Spark y parámetros\n",
    "\n",
    "- Ejecuta local con todos los cores.\n",
    "\n",
    "- Ajusta `DATA_DIR` si tu dataset está en otra ruta.\n",
    "\n",
    "- `TEST_START_YM` define el **corte temporal** principal.\n",
    "\n",
    "- `BACKTEST_SPLITS` permite evaluar **varios cortes** (opcional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bff58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T, Window\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Imputer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"modelado-proximo-pedido-digital-v3\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.sql.warehouse.dir\", \"./spark-warehouse\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "DATA_DIR = \"dataset/dataset\"      # <--- Ajusta si tu ruta cambia\n",
    "TEST_START_YM = \"2024-01\"         # Entrena con ym < TEST_START_YM | Evalúa con ym >= TEST_START_YM\n",
    "BACKTEST_SPLITS = [\"2023-08\", \"2023-10\", \"2023-12\", \"2024-01\"]  # Opcional\n",
    "\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc3649",
   "metadata": {},
   "source": [
    "## 2) Carga y preparación mínima\n",
    "\n",
    "- Derivamos `month_first`, `ym` y `is_digital`.\n",
    "\n",
    "- Mantenemos **nombres simples** y tipos adecuados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca290975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(DATA_DIR)\n",
    "\n",
    "expected = [\n",
    "    \"cliente_id\",\"pais_cd\",\"region_comercial_txt\",\"agencia_id\",\"ruta_id\",\n",
    "    \"tipo_cliente_cd\",\"madurez_digital_cd\",\"estrellas_txt\",\"frecuencia_visitas_cd\",\n",
    "    \"fecha_pedido_dt\",\"canal_pedido_cd\",\"facturacion_usd_val\",\n",
    "    \"materiales_distintos_val\",\"cajas_fisicas\"\n",
    "]\n",
    "present = [c for c in expected if c in df.columns]\n",
    "print(\"Columnas presentes:\", present)\n",
    "\n",
    "df = (df\n",
    "    .withColumn(\"month_first\", F.trunc(\"fecha_pedido_dt\", \"month\"))\n",
    "    .withColumn(\"ym\", F.date_format(\"month_first\", \"yyyy-MM\"))\n",
    "    .withColumn(\"is_digital\", F.when(F.col(\"canal_pedido_cd\")==\"DIGITAL\", 1).otherwise(0))\n",
    ")\n",
    "\n",
    "df.select(\"cliente_id\",\"fecha_pedido_dt\",\"ym\",\"canal_pedido_cd\",\"is_digital\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1afda5",
   "metadata": {},
   "source": [
    "## 3) Etiqueta por **cliente-mes** (determinista, sin fuga)\n",
    "\n",
    "- Orden por `fecha_pedido_dt` (y *tie-break* con hash de todas las columnas).\n",
    "\n",
    "- Para cada mes de un cliente, tomamos el **último pedido** y definimos `label` como si el **próximo pedido** del cliente es DIGITAL.\n",
    "\n",
    "- Agregamos `recency_days_last` (días desde el pedido previo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95849115",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = df.columns\n",
    "w_client_order = Window.partitionBy(\"cliente_id\").orderBy(F.col(\"fecha_pedido_dt\").asc(),\n",
    "                                                          F.hash(*[F.col(c) for c in all_cols]).asc())\n",
    "w_client_month_desc = Window.partitionBy(\"cliente_id\",\"month_first\").orderBy(F.col(\"fecha_pedido_dt\").desc(),\n",
    "                                                                             F.hash(*[F.col(c) for c in all_cols]).desc())\n",
    "\n",
    "orders = (df\n",
    "    .withColumn(\"prev_dt\", F.lag(\"fecha_pedido_dt\").over(w_client_order))\n",
    "    .withColumn(\"next_canal\", F.lead(\"canal_pedido_cd\").over(w_client_order))\n",
    "    .withColumn(\"next_is_digital\", F.when(F.col(\"next_canal\")==\"DIGITAL\", 1).otherwise(0))\n",
    "    .withColumn(\"recency_days\", F.datediff(F.col(\"fecha_pedido_dt\"), F.col(\"prev_dt\")))\n",
    "    .withColumn(\"rn_month_desc\", F.row_number().over(w_client_month_desc))\n",
    ")\n",
    "\n",
    "last_in_month = (orders\n",
    "    .filter(F.col(\"rn_month_desc\")==1)\n",
    "    .select(\"cliente_id\",\"month_first\",\"ym\",\n",
    "            F.col(\"recency_days\").alias(\"recency_days_last\"),\n",
    "            F.col(\"next_is_digital\").alias(\"label\"))\n",
    ")\n",
    "\n",
    "last_in_month.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4eec2",
   "metadata": {},
   "source": [
    "## 4) Feature engineering (RFM + rolling + ciclo de vida + priors de segmento)\n",
    "\n",
    "**Señales por cliente-mes**:\n",
    "\n",
    "- Volumen/valor: `n_orders`, `sum_fact`, `avg_fact`, `sum_cajas`, `avg_cajas`, `avg_mat_dist`.\n",
    "\n",
    "- Comportamiento: `digital_ratio` del mes, `lag1_digital_ratio`, **rolling 3m** y `growth_digital_ratio`.\n",
    "\n",
    "- Ciclo de vida: meses desde primer pedido (`months_since_first`).\n",
    "\n",
    "- Priors de segmento (históricos): `region_digital_ratio_lag1`, `tipo_cliente_digital_ratio_lag1`.\n",
    "\n",
    "*(las razones/ratios de segmento se calculan por mes y se desplazan un mes hacia atrás para evitar fuga)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0956987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregados cliente-mes\n",
    "monthly_agg = (df.groupBy(\"cliente_id\",\"month_first\",\"ym\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"n_orders\"),\n",
    "        F.avg(\"is_digital\").alias(\"digital_ratio\"),\n",
    "        F.sum(F.col(\"facturacion_usd_val\").cast(\"double\")).alias(\"sum_fact\"),\n",
    "        F.avg(F.col(\"facturacion_usd_val\").cast(\"double\")).alias(\"avg_fact\"),\n",
    "        F.sum(F.col(\"cajas_fisicas\").cast(\"double\")).alias(\"sum_cajas\"),\n",
    "        F.avg(F.col(\"cajas_fisicas\").cast(\"double\")).alias(\"avg_cajas\"),\n",
    "        F.avg(F.col(\"materiales_distintos_val\").cast(\"double\")).alias(\"avg_mat_dist\"),\n",
    "        F.first(\"tipo_cliente_cd\", ignorenulls=True).alias(\"tipo_cliente_cd\"),\n",
    "        F.first(\"madurez_digital_cd\", ignorenulls=True).alias(\"madurez_digital_cd\"),\n",
    "        F.first(\"frecuencia_visitas_cd\", ignorenulls=True).alias(\"frecuencia_visitas_cd\"),\n",
    "        F.first(\"pais_cd\", ignorenulls=True).alias(\"pais_cd\"),\n",
    "        F.first(\"region_comercial_txt\", ignorenulls=True).alias(\"region_comercial_txt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ciclo de vida: meses desde primer pedido\n",
    "w_client_month = Window.partitionBy(\"cliente_id\").orderBy(F.col(\"month_first\").asc())\n",
    "first_month = (monthly_agg\n",
    "               .withColumn(\"first_month\", F.first(\"month_first\", ignorenulls=True).over(w_client_month))\n",
    "               .select(\"cliente_id\",\"first_month\").distinct())\n",
    "\n",
    "monthly_agg = monthly_agg.join(first_month, on=\"cliente_id\", how=\"left\")                          .withColumn(\"months_since_first\", F.floor(F.months_between(\"month_first\", \"first_month\")))\n",
    "\n",
    "# Ratios por segmento (mes a mes) y lag para evitar fuga\n",
    "region_month = (df.groupBy(\"region_comercial_txt\",\"month_first\")\n",
    "                  .agg(F.avg(\"is_digital\").alias(\"region_digital_ratio\")))\n",
    "region_month = region_month.withColumn(\"ym\", F.date_format(\"month_first\", \"yyyy-MM\"))\n",
    "w_region = Window.partitionBy(\"region_comercial_txt\").orderBy(F.col(\"month_first\").asc())\n",
    "region_month = region_month.withColumn(\"region_digital_ratio_lag1\", F.lag(\"region_digital_ratio\", 1).over(w_region))                            .select(\"region_comercial_txt\",\"ym\",\"region_digital_ratio_lag1\")\n",
    "\n",
    "tipo_month = (df.groupBy(\"tipo_cliente_cd\",\"month_first\")\n",
    "                .agg(F.avg(\"is_digital\").alias(\"tipo_digital_ratio\")))\n",
    "tipo_month = tipo_month.withColumn(\"ym\", F.date_format(\"month_first\", \"yyyy-MM\"))\n",
    "w_tipo = Window.partitionBy(\"tipo_cliente_cd\").orderBy(F.col(\"month_first\").asc())\n",
    "tipo_month = tipo_month.withColumn(\"tipo_digital_ratio_lag1\", F.lag(\"tipo_digital_ratio\", 1).over(w_tipo))                        .select(\"tipo_cliente_cd\",\"ym\",\"tipo_digital_ratio_lag1\")\n",
    "\n",
    "# Construcción del dataset con label\n",
    "w_roll3 = w_client_month.rowsBetween(-3, -1)  # 3 meses previos\n",
    "ds = (monthly_agg\n",
    "    .join(last_in_month, on=[\"cliente_id\",\"month_first\",\"ym\"], how=\"left\")\n",
    "    .withColumn(\"lag1_digital_ratio\", F.lag(\"digital_ratio\", 1).over(w_client_month))\n",
    "    .withColumn(\"n_orders_3m\", F.sum(\"n_orders\").over(w_roll3))\n",
    "    .withColumn(\"digital_ratio_3m\", F.avg(\"digital_ratio\").over(w_roll3))\n",
    "    .withColumn(\"sum_fact_3m\", F.sum(\"sum_fact\").over(w_roll3))\n",
    "    .withColumn(\"growth_digital_ratio\", F.col(\"digital_ratio\") - F.col(\"lag1_digital_ratio\"))\n",
    "    .join(region_month, on=[\"region_comercial_txt\",\"ym\"], how=\"left\")\n",
    "    .join(tipo_month, on=[\"tipo_cliente_cd\",\"ym\"], how=\"left\")\n",
    "    .filter(F.col(\"label\").isNotNull())\n",
    ")\n",
    "\n",
    "ds.select(\"cliente_id\",\"ym\",\"n_orders\",\"digital_ratio\",\"lag1_digital_ratio\",\n",
    "          \"n_orders_3m\",\"digital_ratio_3m\",\"growth_digital_ratio\",\n",
    "          \"months_since_first\",\"region_digital_ratio_lag1\",\"tipo_digital_ratio_lag1\",\n",
    "          \"label\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d4426",
   "metadata": {},
   "source": [
    "## 5) Split temporal y **balance de clases**\n",
    "\n",
    "- Train: `ym < TEST_START_YM`.\n",
    "\n",
    "- Test:  `ym >= TEST_START_YM`.\n",
    "\n",
    "- Mostramos la **distribución de la etiqueta** y aplicamos **weightCol** cuando hay desbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86757644",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ds.filter(F.col(\"ym\") < F.lit(TEST_START_YM))\n",
    "test  = ds.filter(F.col(\"ym\") >= F.lit(TEST_START_YM))\n",
    "\n",
    "print(\"Train rows:\", train.count(), \" | Test rows:\", test.count())\n",
    "print(\"\\nDistribución de la etiqueta:\")\n",
    "for name, d in [(\"train\", train), (\"test\", test)]:\n",
    "    print(f\"--- {name} ---\")\n",
    "    d.groupBy(\"label\").count().orderBy(\"label\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38571ab",
   "metadata": {},
   "source": [
    "## 6) Pipeline de modelado (reutilizable)\n",
    "\n",
    "- Imputación para numéricas, Indexación+OneHot para categóricas, `VectorAssembler`.\n",
    "\n",
    "- Modelos soportados: `lr`, `rf`, `gbt`.\n",
    "\n",
    "- **TrainValidationSplit** con *grid* compacto.\n",
    "\n",
    "- **weightCol** para balancear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69db0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"n_orders\",\"digital_ratio\",\"lag1_digital_ratio\",\"sum_fact\",\"avg_fact\",\n",
    "            \"sum_cajas\",\"avg_cajas\",\"avg_mat_dist\",\"recency_days_last\",\n",
    "            \"n_orders_3m\",\"digital_ratio_3m\",\"sum_fact_3m\",\"growth_digital_ratio\",\n",
    "            \"months_since_first\",\"region_digital_ratio_lag1\",\"tipo_digital_ratio_lag1\"]\n",
    "\n",
    "cat_cols = [\"tipo_cliente_cd\",\"madurez_digital_cd\",\"frecuencia_visitas_cd\",\"pais_cd\",\"region_comercial_txt\"]\n",
    "\n",
    "imputer = Imputer(inputCols=num_cols, outputCols=[c + \"_imp\" for c in num_cols])\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"keep\") for c in cat_cols]\n",
    "encoders = [OneHotEncoder(inputCols=[c + \"_idx\"], outputCols=[c + \"_oh\"]) for c in cat_cols]\n",
    "feature_cols = [c + \"_imp\" for c in num_cols] + [c + \"_oh\" for c in cat_cols]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "def build_and_fit(model_name: str, train_df):\n",
    "    # Balanceo simple\n",
    "    pos = train_df.filter(F.col(\"label\")==1).count()\n",
    "    neg = train_df.filter(F.col(\"label\")==0).count()\n",
    "    balancing_ratio = neg / float(max(pos, 1)) if pos else 1.0\n",
    "    train_w = train_df.withColumn(\"weight\", F.when(F.col(\"label\")==1, F.lit(balancing_ratio)).otherwise(F.lit(1.0)))\n",
    "\n",
    "    if model_name == \"lr\":\n",
    "        clf = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", weightCol=\"weight\",\n",
    "                                 maxIter=80, regParam=0.01, elasticNetParam=0.0)\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                     .addGrid(clf.regParam, [0.0, 0.01, 0.1])\n",
    "                     .addGrid(clf.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "                     .build())\n",
    "    elif model_name == \"rf\":\n",
    "        clf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", weightCol=\"weight\",\n",
    "                                     numTrees=200, maxDepth=10, featureSubsetStrategy=\"sqrt\",\n",
    "                                     subsamplingRate=0.8, seed=42)\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                     .addGrid(clf.numTrees, [150, 200, 300])\n",
    "                     .addGrid(clf.maxDepth, [8, 10, 12])\n",
    "                     .build())\n",
    "    elif model_name == \"gbt\":\n",
    "        clf = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=100, maxDepth=6, stepSize=0.1, seed=42)\n",
    "        # Nota: GBT en Spark no soporta weightCol directamente antes de 3.4; se usa dataset balanceado/estratificado si es necesario.\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                     .addGrid(clf.maxIter, [60, 100])\n",
    "                     .addGrid(clf.maxDepth, [5, 6, 8])\n",
    "                     .build())\n",
    "    else:\n",
    "        raise ValueError(\"Modelo no soportado\")\n",
    "\n",
    "    pipeline = Pipeline(stages=[imputer] + indexers + encoders + [assembler, clf])\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "    tvs = TrainValidationSplit(estimator=pipeline, estimatorParamMaps=paramGrid,\n",
    "                               evaluator=evaluator, trainRatio=0.8, parallelism=2)\n",
    "\n",
    "    tvs_model = tvs.fit(train_w if model_name in (\"lr\",\"rf\") else train_df)  # GBT sin weights\n",
    "    return tvs_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7203fc",
   "metadata": {},
   "source": [
    "## 7) Evaluación: AUC, matriz y métricas derivadas\n",
    "\n",
    "- Reportamos **AUC ROC** y **AUC PR**.\n",
    "\n",
    "- Con el umbral 0.5 para referencia.\n",
    "\n",
    "- Devuelve también las predicciones con la probabilidad `p_digital`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b81a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_df, model_name=\"model\"):\n",
    "    pred = model.transform(test_df).withColumn(\"p_digital\", vector_to_array(\"probability\")[1]).cache()\n",
    "    e_auc  = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "    e_aupr = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "    auc = e_auc.evaluate(pred)\n",
    "    aupr = e_aupr.evaluate(pred)\n",
    "\n",
    "    cm = (pred.groupBy(\"label\",\"prediction\").count().toPandas())\n",
    "    tp = int(cm[(cm[\"label\"]==1) & (cm[\"prediction\"]==1)][\"count\"].sum())\n",
    "    tn = int(cm[(cm[\"label\"]==0) & (cm[\"prediction\"]==0)][\"count\"].sum())\n",
    "    fp = int(cm[(cm[\"label\"]==0) & (cm[\"prediction\"]==1)][\"count\"].sum())\n",
    "    fn = int(cm[(cm[\"label\"]==1) & (cm[\"prediction\"]==0)][\"count\"].sum())\n",
    "\n",
    "    accuracy  = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
    "    precision = tp / max(tp + fp, 1)\n",
    "    recall    = tp / max(tp + fn, 1)\n",
    "    f1        = (2 * precision * recall) / max(precision + recall, 1e-9)\n",
    "\n",
    "    print(f\"[{model_name}]  AUC ROC: {auc:.4f} | AUC PR: {aupr:.4f} | Acc: {accuracy:.4f} | Prec: {precision:.4f} | Rec: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    return pred, {\"auc_roc\": auc, \"auc_pr\": aupr, \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cea1e",
   "metadata": {},
   "source": [
    "## 8) Entrenamiento y comparación de modelos (LR, RF, GBT)\n",
    "\n",
    "Seleccionamos el **mejor** por **AUC PR** (prioriza casos positivos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "predictions = {}\n",
    "\n",
    "for name in [\"lr\",\"rf\",\"gbt\"]:\n",
    "    print(f\"Entrenando modelo: {name}\")\n",
    "    m = build_and_fit(name, train)\n",
    "    pred, mtx = evaluate_model(m, test, model_name=name)\n",
    "    models[name] = m\n",
    "    metrics[name] = mtx\n",
    "    predictions[name] = pred.select(\"cliente_id\",\"ym\",\"label\",\"p_digital\")\n",
    "\n",
    "# Selección por AUC PR\n",
    "best_name = sorted(metrics.items(), key=lambda x: x[1][\"auc_pr\"], reverse=True)[0][0]\n",
    "best_model = models[best_name]\n",
    "best_pred  = predictions[best_name]\n",
    "\n",
    "print(\"\\n>>> Mejor modelo por AUC PR:\", best_name, metrics[best_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dec5ac",
   "metadata": {},
   "source": [
    "## 9) Tuning de umbral (max F1)\n",
    "\n",
    "Buscamos el umbral óptimo para el **mejor modelo**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_with_threshold_from_pred(pred_df, thr: float):\n",
    "    p = pred_df.withColumn(\"pred_thr\", (F.col(\"p_digital\") >= F.lit(thr)).cast(\"int\"))\n",
    "    agg = p.agg(\n",
    "        F.sum(F.when((F.col(\"label\")==1) & (F.col(\"pred_thr\")==1), 1).otherwise(0)).alias(\"tp\"),\n",
    "        F.sum(F.when((F.col(\"label\")==0) & (F.col(\"pred_thr\")==0), 1).otherwise(0)).alias(\"tn\"),\n",
    "        F.sum(F.when((F.col(\"label\")==0) & (F.col(\"pred_thr\")==1), 1).otherwise(0)).alias(\"fp\"),\n",
    "        F.sum(F.when((F.col(\"label\")==1) & (F.col(\"pred_thr\")==0), 1).otherwise(0)).alias(\"fn\")\n",
    "    ).first()\n",
    "    tp, tn, fp, fn = [float(agg[x] or 0.0) for x in (\"tp\",\"tn\",\"fp\",\"fn\")]\n",
    "    total = tp + tn + fp + fn or 1.0\n",
    "    accuracy  = (tp + tn) / total\n",
    "    precision = tp / (tp + fp or 1.0)\n",
    "    recall    = tp / (tp + fn or 1.0)\n",
    "    f1        = (2 * precision * recall) / (precision + recall or 1e-9)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "grid = [x/100 for x in range(30, 81, 5)]\n",
    "rows = []\n",
    "for t in grid:\n",
    "    acc, pre, rec, f1 = metrics_with_threshold_from_pred(best_pred, t)\n",
    "    rows.append((t, acc, pre, rec, f1))\n",
    "\n",
    "thr_df = spark.createDataFrame(rows, [\"threshold\",\"accuracy\",\"precision\",\"recall\",\"f1\"]).orderBy(F.desc(\"f1\"))\n",
    "thr_df.show(20, False)\n",
    "\n",
    "best_thr = thr_df.first()[\"threshold\"]\n",
    "acc, pre, rec, f1 = metrics_with_threshold_from_pred(best_pred, best_thr)\n",
    "print(f\"Mejor threshold: {best_thr:.2f} | Acc: {acc:.4f}  Prec: {pre:.4f}  Rec: {rec:.4f}  F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd06f7",
   "metadata": {},
   "source": [
    "## 10) Métricas por segmento (país / región)\n",
    "\n",
    "Evalúa **dónde** funciona mejor el modelo (AUC por grupo). Se omiten segmentos con una sola clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = (best_pred.join(test.select(\"cliente_id\",\"ym\",\"pais_cd\",\"region_comercial_txt\"),\n",
    "                           on=[\"cliente_id\",\"ym\"], how=\"left\"))\n",
    "\n",
    "def auc_by_group(df_in, group_col: str):\n",
    "    df_in = df_in.filter(F.col(group_col).isNotNull())\n",
    "    groups = [r[0] for r in df_in.select(group_col).distinct().collect()]\n",
    "    e_auc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"p_digital\", metricName=\"areaUnderROC\")\n",
    "    out = []\n",
    "    for g in groups:\n",
    "        subset = df_in.filter(F.col(group_col)==g)\n",
    "        if subset.select(\"label\").distinct().count() < 2:\n",
    "            continue\n",
    "        # Como 'p_digital' es probabilidad, usamos el evaluador con probabilidades: necesita una columna de rawPrediction.\n",
    "        # Truco: crear una columna vector con forma [1-p, p] sólo para el evaluador.\n",
    "        sub2 = subset.withColumn(\"rawPrediction\", F.array(1.0 - F.col(\"p_digital\"), F.col(\"p_digital\")))\n",
    "        auc_g = e_auc.evaluate(sub2)\n",
    "        out.append((g, float(auc_g)))\n",
    "    return spark.createDataFrame(out, [group_col, \"auc_roc\"]).orderBy(F.desc(\"auc_roc\"))\n",
    "\n",
    "print(\"AUC ROC por país:\")\n",
    "auc_by_group(joined, \"pais_cd\").show(truncate=False)\n",
    "\n",
    "print(\"AUC ROC por región:\")\n",
    "auc_by_group(joined, \"region_comercial_txt\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291c625",
   "metadata": {},
   "source": [
    "## 11) Calibración de probabilidad (curva de confiabilidad)\n",
    "\n",
    "- Particionamos por **deciles** de probabilidad (`p_digital`).\n",
    "\n",
    "- Mostramos **promedio predicho vs. observado** por bin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84aa254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntile(10) sobre probabilidad\n",
    "w_prob = Window.orderBy(F.col(\"p_digital\").asc())\n",
    "calib = (best_pred\n",
    "         .withColumn(\"decile\", F.ntile(10).over(w_prob))\n",
    "         .groupBy(\"decile\")\n",
    "         .agg(F.avg(\"p_digital\").alias(\"p_pred_mean\"),\n",
    "              F.avg(F.col(\"label\").cast(\"double\")).alias(\"p_obs_mean\"),\n",
    "              F.count(\"*\").alias(\"n\"))\n",
    "         .orderBy(\"decile\"))\n",
    "\n",
    "calib.show(10, False)\n",
    "\n",
    "# Plot opcional (si tienes matplotlib)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    pdf = calib.toPandas()\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(pdf[\"p_pred_mean\"], pdf[\"p_obs_mean\"], marker=\"o\")\n",
    "    plt.plot([0,1],[0,1],\"--\")\n",
    "    plt.title(\"Curva de calibración\")\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Observado\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Plot no disponible (matplotlib no instalado):\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd90eb",
   "metadata": {},
   "source": [
    "## 12) Backtesting (opcional)\n",
    "\n",
    "Repite entrenamiento/evaluación en múltiples cortes temporales (`BACKTEST_SPLITS`) para verificar **estabilidad**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split(ym_cut):\n",
    "    train_bt = ds.filter(F.col(\"ym\") < F.lit(ym_cut))\n",
    "    test_bt  = ds.filter(F.col(\"ym\") >= F.lit(ym_cut))\n",
    "    m = build_and_fit(best_name, train_bt)\n",
    "    pred_bt, mtx_bt = evaluate_model(m, test_bt, model_name=f\"{best_name}@{ym_cut}\")\n",
    "    return ym_cut, mtx_bt\n",
    "\n",
    "bt_rows = []\n",
    "for cut in BACKTEST_SPLITS:\n",
    "    try:\n",
    "        ym_cut, mtx = run_split(cut)\n",
    "        bt_rows.append((ym_cut, float(mtx[\"auc_pr\"]), float(mtx[\"auc_roc\"]), float(mtx[\"f1\"])))\n",
    "    except Exception as e:\n",
    "        print(f\"Backtest falló en corte {cut}:\", e)\n",
    "\n",
    "if bt_rows:\n",
    "    bt_df = spark.createDataFrame(bt_rows, [\"ym_cut\",\"auc_pr\",\"auc_roc\",\"f1\"]).orderBy(\"ym_cut\")\n",
    "    bt_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891a5d0",
   "metadata": {},
   "source": [
    "## 13) Exportar artefactos y métricas\n",
    "\n",
    "- Guarda el **mejor modelo** (`models/`).\n",
    "\n",
    "- Guarda **métricas** y **predicciones** (`results/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016381a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo\n",
    "models_dir = f\"models/{best_name}_next_digital_v3\"\n",
    "best_model.bestModel.write().overwrite().save(models_dir)\n",
    "\n",
    "# Guardar métricas globales\n",
    "from datetime import datetime\n",
    "metrics_rows = [\n",
    "    (\"model\", best_name),\n",
    "    (\"auc_pr\", float(metrics[best_name][\"auc_pr\"])),\n",
    "    (\"auc_roc\", float(metrics[best_name][\"auc_roc\"])),\n",
    "    (\"accuracy\", float(metrics[best_name][\"accuracy\"])),\n",
    "    (\"precision\", float(metrics[best_name][\"precision\"])),\n",
    "    (\"recall\", float(metrics[best_name][\"recall\"])),\n",
    "    (\"f1\", float(metrics[best_name][\"f1\"])),\n",
    "    (\"best_threshold\", float(best_thr)),\n",
    "    (\"generated_at\", datetime.utcnow().isoformat())\n",
    "]\n",
    "spark.createDataFrame([(k, v) for k, v in metrics_rows], [\"metric\",\"value\"]).coalesce(1)      .write.mode(\"overwrite\").json(\"results/metrics_v3\")\n",
    "\n",
    "# Guardar predicciones con probabilidad\n",
    "best_pred.write.mode(\"overwrite\").parquet(\"results/pred_test_v3\")\n",
    "\n",
    "print(\"Modelo guardado en:\", models_dir)\n",
    "print(\"Métricas y predicciones guardadas en 'results/'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5120e10",
   "metadata": {},
   "source": [
    "## 14) Cierre de sesión Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark session stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


# Predicci√≥n del **Pr√≥ximo Pedido DIGITAL** (eB2B)

**Autor:** Wilson Eduardo Jerez Hern√°ndez  
**Fecha:** 2025-09-16

---

## üßæ TL;DR (1 minuto)

- **Objetivo:** estimar la probabilidad de que el **pr√≥ximo pedido** de un cliente sea **DIGITAL** para **priorizar campa√±as**.  
- **Enfoque:** features temporales a nivel **cliente-mes** + **Regresi√≥n Log√≠stica** (PySpark) con manejo de **desbalance** y **backtesting** por cortes de tiempo.  
- **Valor de negocio:** en el **top-10%** de clientes, el modelo ofrece **Lift ‚âà 1.55√ó** (duplica la tasa vs. al azar) con precisi√≥n entre **~48‚Äì58%**.  
- **Listo para explicar:** este README contiene **Qu√© / Por qu√© / C√≥mo**, mini-teor√≠a de **Backtesting**, **AUC ROC/PR**, **PR@k/Lift**, gu√≠a de **demo** y **FAQs**.

---

## 1) Problema & Objetivo

La compa√±√≠a quiere **acelerar la adopci√≥n del canal digital** (eB2B). Con el hist√≥rico de pedidos por cliente, construimos un modelo que **rankea** clientes por su probabilidad de que **el pr√≥ximo pedido** sea **DIGITAL**.

**Objetivo operativo:** seleccionar **top-k%** clientes (seg√∫n score) para **campa√±as** con mayor conversi√≥n esperada.  

> **Por qu√© ‚Äúpr√≥ximo‚Äù y no ‚Äúactual‚Äù**: el equipo de marketing decide **hoy** a qui√©n contactar; por lo tanto, la predicci√≥n debe mirar **solo el pasado** y anticipar el **siguiente** comportamiento.

---

## 2) Datos & Preparaci√≥n (Qu√© / Por qu√© / C√≥mo)

**Nivel de trabajo:** `cliente_id √ó mes` (columna `ym`).

**Campos m√≠nimos esperados (ejemplo):**  
`cliente_id, pais_cd, fecha_pedido_dt, canal_pedido_cd, facturacion_usd_val, materiales_distintos_val, cajas_fisicas, frecuencia_visitas_cd, ...`

**Normalizaci√≥n temporal (C√≥mo):**
- `month_first = trunc(fecha_pedido_dt, 'month')`
- `ym = date_format(month_first, 'yyyy-MM')`
- `is_digital = 1{canal_pedido_cd == 'DIGITAL'} else 0`

**¬øPor qu√© a cliente-mes?**  
- Facilita **features temporales** (rolling/recencia).  
- Evita mezclar observaciones de distinta granularidad.  
- Alinea la **ventana de decisi√≥n** con el uso real (campa√±as mensuales o quincenales).

---

## 3) Etiquetado **sin fuga** (Qu√© / Por qu√© / C√≥mo)

- **Qu√©:** por cada `cliente_id` y mes, tomamos el **√∫ltimo pedido** del mes.  
  La **etiqueta** (`label`) vale **1** si el **siguiente pedido** del cliente fue **DIGITAL** (si no, **0**).
- **Por qu√©:** queremos saber si **el pr√≥ximo** pedido ser√° digital; usar informaci√≥n del mismo mes para etiquetar introducir√≠a **fuga** (*leakage*).
- **C√≥mo:**  
  - Ventana ordenada por `fecha_pedido_dt`: `lead(canal_pedido_cd)` da el canal del **siguiente pedido**.  
  - Dentro del mes, `row_number()` descendente para quedarnos con **el √∫ltimo** pedido del mes.  
  - La recencia se calcula con `lag(fecha_pedido_dt)` ‚Üí `recency_days_last`.

---

## 4) Features (Qu√© / Por qu√© / C√≥mo)

**Grupos de se√±ales**:
1. **Actividad y valor (RFM light):**  
   - `n_orders`, `sum_fact`, `avg_fact`, `sum_cajas`, `avg_cajas`, `avg_mat_dist`.
2. **Comportamiento digital propio:**  
   - `digital_ratio` (del mes), `lag1_digital_ratio`, `digital_ratio_3m`, `growth_digital_ratio`.
3. **Ciclo de vida:**  
   - `months_since_first` (meses desde el primer pedido del cliente).
4. **Contexto del segmento (priors):**  
   - `region_digital_ratio_lag1`, `tipo_digital_ratio_lag1` (lag del ratio DIGITAL por **regi√≥n** y **tipo_cliente**).
5. **Categ√≥ricas de baja cardinalidad:**  
   - `madurez_digital_cd`, `frecuencia_visitas_cd`, `pais_cd`, `tipo_cliente_cd` ‚Üí **OHE**.

**Por qu√© estos features:** combinan **se√±ales propias** del cliente, **tendencias** recientes y **contexto** de su segmento, claves para **ranking**.

---

## 5) Modelo & Entrenamiento

- **Modelo base:** **Regresi√≥n Log√≠stica** (PySpark) por **estabilidad, velocidad y explicabilidad**.  
- **Desbalance de clases:** la clase `1 = DIGITAL` suele ser minoritaria. Se implementan 3 estrategias:  
  1) `weightCol` (por defecto), 2) **oversampling** de positivos, 3) **undersampling** de negativos.  
- **Grid sencillo:** `regParam ‚àà {0, 0.01, 0.1}`, `elasticNetParam ‚àà {0, 0.5, 1}` con `TrainValidationSplit`.  
- **M√©trica de tuning:** **AUC PR** (m√°s sensible a desbalance que AUC ROC).

> **Explicabilidad**: con LR se pueden inspeccionar **coeficientes** (signo/magnitud). √ötil para insights de negocio (con precauci√≥n por colinealidad).

---

## 6) Validaci√≥n Temporal (**Backtesting**)

**Qu√©**: simular el desempe√±o del modelo **en el pasado** como si lo hubi√©ramos desplegado all√≠.  
**C√≥mo**: para cada corte `TEST_START_YM`, entrenar con `ym < corte` y evaluar en `ym ‚â• corte`.  
**Por qu√©**: los datos cambian; el backtesting prueba **robustez temporal**.

**Cortes usados:** `2023-08`, `2023-10`, `2023-12`, `2024-01`  
**Entorno:** Spark **4.0.1**.  
**Tama√±o agregado (cliente-mes):** ~**1,022,849** filas.

---

## 7) M√©tricas & Resultados

### Mini-teor√≠a
- **AUC ROC**: √°rea bajo la curva TPR vs FPR; **separaci√≥n global** (1.0 perfecto, 0.5 azar).  
- **AUC PR**: √°rea bajo Precisi√≥n vs Recall; **m√°s informativa** en **desbalance**.  
- **PR@k**: precisi√≥n en el **top k%** por score.  
- **Recall@k**: fracci√≥n de positivos capturada en ese **top k%**.  
- **Lift@k = PR@k / tasa_base**: cu√°ntas veces mejor que al azar.  
- **F1**: 2¬∑(Precision¬∑Recall)/(Precision+Recall) ‚Äî se reporta al **umbral √≥ptimo**.

### Backtesting (estrategia `weights`)
| Corte | AUC ROC | AUC PR | Umbral F1 | F1@Umbral | PR@5% | Lift@5% | PR@10% | Lift@10% |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| 2023-08 | 0.6233 | 0.4997 | 0.00 | 0.5422 | 0.5796 | 1.5582 | 0.5790 | 1.5566 |
| 2023-10 | 0.6196 | 0.4735 | 0.38 | 0.5236 | 0.5492 | 1.5578 | 0.5478 | 1.5539 |
| 2023-12 | 0.6146 | 0.4375 | 0.38 | 0.4993 | 0.5100 | 1.5651 | 0.5067 | 1.5548 |
| 2024-01 | 0.6119 | 0.4135 | 0.38 | 0.4823 | 0.4829 | 1.5697 | 0.4791 | 1.5571 |

**Lecturas clave**  
- **Estabilidad**: rendimiento **consistente** entre cortes (ligera degradaci√≥n esperable).  
- **Valor para campa√±as**: **Lift ‚âà 1.55√ó** en top-5‚Äì10% ‚Üí **duplica** la efectividad frente a contactar al azar.  
- **Precisi√≥n top-k**: ~**48‚Äì58%** en top-10% (seg√∫n corte).  
- **AUC PR** disminuye en cortes recientes ‚Üí posible **drift**; sugiere **reentrenos**.

---

## 8) Hallazgos

1) El enfoque **ranker** (probabilidad ‚Üí top-k) es **√∫til** para priorizar clientes en campa√±as con presupuesto limitado.  
2) **Se√±ales econ√≥micas** (p. ej., `avg_fact_imp`) y **tendencias** (`digital_ratio_3m`, `growth_digital_ratio`) aportan a la discriminaci√≥n.  
3) Los **priors de segmento** (regi√≥n/tipo) ayudan a capturar patrones contextuales.  
4) La **optimizaci√≥n por AUC PR** y el reporte de **PR@k/Lift** son mejores para **desbalance** que accuracy.

---

## 9) C√≥mo ejecutar (reproducibilidad)

### Requisitos
- Python 3.10+  
- PySpark (probado en Spark 4.0.1)

```bash
# instalar dependencias
pip install -r requirements.txt
```

### Datos
- Coloca los archivos en `dataset/` (por defecto en los notebooks).  
- Si tu ruta cambia, edita `DATA_DIR` al inicio del notebook de modelado.

### Pasos
1) Abre y corre **EDA.ipynb** para validar esquema/distribuciones.  
2) Abre y corre **02_Modelado** (notebook):  
   - Ajusta `BACKTEST_SPLITS` si quieres otros cortes.  
   - Para pruebas r√°pidas: baja `spark.sql.shuffle.partitions` y/o reduce el **grid** del modelo.  
3) (Opcional) Genera **scores** y exporta **top-k** clientes para campa√±a.

> **Estabilidad**: el notebook usa **Kryo**, incrementa **memoria**, y aplica `checkpoint(eager=True)` para cortar linajes de Spark y evitar OOM.

---

## 10) Uso en campa√±as (c√≥mo accionar)

1) Ordena clientes por `p1` (probabilidad de pedido DIGITAL).  
2) Selecciona **top-k%** seg√∫n tu presupuesto/contactabilidad.  
3) Usa **PR@k** y **Lift@k** para estimar **impacto** (conversi√≥n esperada y ROI).  
4) Ajusta el **umbral** seg√∫n tu objetivo:  
   - **Mayor eficiencia** ‚Üí sube el umbral (m√°s precisi√≥n, menos cobertura).  
   - **Mayor cobertura** ‚Üí b√°jalo (m√°s recall, menor precisi√≥n).

---

## 11) Limitaciones

- **Modelo lineal** (LR): robusto y explicable, pero puede no capturar **no linealidades** complejas.  
- **Drift temporal**: ca√≠da leve de AUC PR en cortes recientes; requiere **monitoreo** y **reentrenos**.  
- **Features mejorables**:  
  - Rolling √∫nicamente 3m (a√±adir 1/6/12m y *expanding windows*).  
  - Priors de segmento con m√°s granularidad y **tendencias**.  
  - Posibles **interacciones** (valor √ó recencia, tipo √ó regi√≥n).  
- **Calidad/Disponibilidad de datos**: outliers o huecos por segmento/pa√≠s pueden afectar estabilidad.

---

## 12) Hoja de ruta (mejoras)

**Modelado**
- Probar **LightGBM/XGBoost** (o √°rboles Spark) para **no linealidad** e **interacciones**.  
- **Calibraci√≥n** de probabilidades (Platt/Isot√≥nica) para decisiones basadas en umbral.  
- **Ensamblados / Stacking**: usar LR como √∫ltima capa explicable.

**Features**
- M√°s ventanas temporales (1/6/12m), m√∫ltiples lags, estacionalidad.  
- Se√±ales de **recencia** enriquecidas y **frecuencia**.  
- Interacciones y **ratios** compuestos.

**Validaci√≥n / Producci√≥n**
- **Monitoreo de drift** (PSI/KS mensuales) y **alertas**.  
- Backtesting **mensual** o *rolling windows*.  
- **MLOps**: versionado de artefactos, *feature store*, CI/CD para reentrenos.

---

## 13) Mapa del repositorio

```
next-digital-order-eb2b/
‚îú‚îÄ dataset/                         # datos parquet/csv (ajusta ruta en notebooks)
‚îú‚îÄ nootbooks/
‚îÇ  ‚îú‚îÄ 01_EDA.ipynb                  # exploraci√≥n y sanidad de datos
‚îÇ  ‚îú‚îÄ 02_Modelado.ipynb             # LR + desbalance + backtesting + PR@k
‚îÇ  ‚îî‚îÄ 02_Modelado_explicado.ipynb   # versi√≥n con celdas "Qu√©/Por qu√©/C√≥mo" y mini-teor√≠a
‚îú‚îÄ requirements.txt                 # dependencias
‚îî‚îÄ README.md                        # este documento
```

---

## 14) Gu√≠a breve para presentar (5‚Äì7 minutos)

1) **Problema y m√©trica de decisi√≥n (1 min)**  
   - ‚ÄúQueremos priorizar clientes con alta prob. de pr√≥ximo pedido **DIGITAL**.‚Äù  
   - M√©tricas de negocio: **PR@k** y **Lift@k** (impacto en campa√±as).

2) **C√≥mo evitamos fuga y c√≥mo hacemos features (2 min)**  
   - Etiquetado por **cliente-mes** con **siguiente** pedido.  
   - Features: actividad/valor, tendencia, ciclo de vida y priors de segmento.

3) **Modelo y validaci√≥n temporal (2 min)**  
   - LR con `weightCol`, backtesting en cortes de tiempo.  
   - Mostrar tabla de m√©tricas y resaltar **Lift ‚âà 1.55√ó**.

4) **Hallazgos y next steps (1‚Äì2 min)**  
   - Qu√© funciona (se√±ales de valor/tendencia), qu√© mejorar (no linealidad, m√°s ventanas, calibraci√≥n).  
   - C√≥mo usar top-k en campa√±as y estimar ROI.

---

## 15) FAQ (r√°pidas)

- **¬øPor qu√© LR y no XGBoost?**  
  Empezamos por LR por **rapidez/estabilidad/explicabilidad**. El roadmap contempla **√°rboles graduales** si hay presupuesto de complejidad.

- **¬øPor qu√© AUC PR y PR@k?**  
  En desbalance, son **m√°s fieles** que accuracy/AUC ROC para medir impacto operativo.

- **¬øCada cu√°nto reentrenar?**  
  Sugerencia: **mensual** o cuando se detecte **drift** en AUC PR/PR@k.

---

**Contacto:** edujerezwilson@gmail.com

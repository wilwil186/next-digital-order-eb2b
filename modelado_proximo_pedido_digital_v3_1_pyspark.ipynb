{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelado — Próximo pedido **DIGITAL** (v3.1, 100% PySpark + Backtesting & Ensembles)\n",
        "\n",
        "**Objetivo:** predecir si el **próximo pedido** de un cliente será **DIGITAL**.\n",
        "\n",
        "**Fecha de generación del cuaderno:** 2025-09-17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Sesión Spark y parámetros\n",
        "\n",
        "- Ejecuta local con todos los cores.\n",
        "- Ajusta `DATA_DIR` si tu dataset está en otra ruta.\n",
        "- `TEST_START_YM` define el **corte temporal** principal.\n",
        "- `BACKTEST_SPLITS` permite evaluar **varios cortes** (opcional).\n",
        "- **Memoria**: subimos `spark.driver.memory` y activamos Kryo para evitar OOM en árboles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession, functions as F, types as T, Window\n",
        "from pyspark import StorageLevel\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Imputer, VectorIndexer, FeatureHasher\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "\n",
        "# Crea/reinicia sesión\n",
        "try:\n",
        "    spark.stop()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"modelado-proximo-pedido-digital-v3.1\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
        "    .config(\"spark.driver.memory\", \"12g\")              # subir si tu máquina lo permite (8–16g)\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
        "    .config(\"spark.kryoserializer.buffer\", \"32m\")\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"512m\")\n",
        "    .config(\"spark.sql.warehouse.dir\", \"./spark-warehouse\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "spark.sparkContext.setCheckpointDir(\"/tmp/spark_chk\")\n",
        "\n",
        "DATA_DIR = \"dataset/dataset\"      # <--- Ajusta si tu ruta cambia\n",
        "TEST_START_YM = \"2024-01\"         # Entrena con ym < TEST_START_YM | Evalúa con ym >= TEST_START_YM\n",
        "BACKTEST_SPLITS = [\"2023-08\", \"2023-10\", \"2023-12\", \"2024-01\"]  # Opcional\n",
        "\n",
        "print(\"Spark version:\", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Carga y preparación mínima\n",
        "\n",
        "- Derivamos `month_first`, `ym` y `is_digital`.\n",
        "- Mantenemos **nombres simples** y tipos adecuados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df = spark.read.parquet(DATA_DIR)\n",
        "\n",
        "expected = [\n",
        "    \"cliente_id\",\"pais_cd\",\"region_comercial_txt\",\"agencia_id\",\"ruta_id\",\n",
        "    \"tipo_cliente_cd\",\"madurez_digital_cd\",\"estrellas_txt\",\"frecuencia_visitas_cd\",\n",
        "    \"fecha_pedido_dt\",\"canal_pedido_cd\",\"facturacion_usd_val\",\n",
        "    \"materiales_distintos_val\",\"cajas_fisicas\"\n",
        "]\n",
        "present = [c for c in expected if c in df.columns]\n",
        "print(\"Columnas presentes:\", present)\n",
        "\n",
        "df = (df\n",
        "    .withColumn(\"month_first\", F.trunc(\"fecha_pedido_dt\", \"month\"))\n",
        "    .withColumn(\"ym\", F.date_format(\"month_first\", \"yyyy-MM\"))\n",
        "    .withColumn(\"is_digital\", F.when(F.col(\"canal_pedido_cd\")==\"DIGITAL\", 1).otherwise(0))\n",
        ")\n",
        "\n",
        "df.select(\"cliente_id\",\"fecha_pedido_dt\",\"ym\",\"canal_pedido_cd\",\"is_digital\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Etiqueta por **cliente-mes** (determinista, sin fuga)\n",
        "\n",
        "- Orden por `fecha_pedido_dt` (y *tie-break* con hash de todas las columnas).\n",
        "- Para cada mes de un cliente, tomamos el **último pedido** y definimos `label` como si el **próximo pedido** del cliente es DIGITAL.\n",
        "- Agregamos `recency_days_last` (días desde el pedido previo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "all_cols = df.columns\n",
        "w_client_order = Window.partitionBy(\"cliente_id\").orderBy(F.col(\"fecha_pedido_dt\").asc(),\n",
        "                                                          F.hash(*[F.col(c) for c in all_cols]).asc())\n",
        "w_client_month_desc = Window.partitionBy(\"cliente_id\",\"month_first\").orderBy(F.col(\"fecha_pedido_dt\").desc(),\n",
        "                                                                             F.hash(*[F.col(c) for c in all_cols]).desc())\n",
        "\n",
        "orders = (df\n",
        "    .withColumn(\"prev_dt\", F.lag(\"fecha_pedido_dt\").over(w_client_order))\n",
        "    .withColumn(\"next_canal\", F.lead(\"canal_pedido_cd\").over(w_client_order))\n",
        "    .withColumn(\"next_is_digital\", F.when(F.col(\"next_canal\")==\"DIGITAL\", 1).otherwise(0))\n",
        "    .withColumn(\"recency_days\", F.datediff(F.col(\"fecha_pedido_dt\"), F.col(\"prev_dt\")))\n",
        "    .withColumn(\"rn_month_desc\", F.row_number().over(w_client_month_desc))\n",
        ")\n",
        "\n",
        "last_in_month = (orders\n",
        "    .filter(F.col(\"rn_month_desc\")==1)\n",
        "    .select(\"cliente_id\",\"month_first\",\"ym\",\n",
        "            F.col(\"recency_days\").alias(\"recency_days_last\"),\n",
        "            F.col(\"next_is_digital\").alias(\"label\"))\n",
        ")\n",
        "\n",
        "last_in_month.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Feature engineering (RFM + rolling + ciclo de vida + priors de segmento)\n",
        "\n",
        "**Señales por cliente-mes**:\n",
        "- Volumen/valor: `n_orders`, `sum_fact`, `avg_fact`, `sum_cajas`, `avg_cajas`, `avg_mat_dist`.\n",
        "- Comportamiento: `digital_ratio` del mes, `lag1_digital_ratio`, **rolling 3m** y `growth_digital_ratio`.\n",
        "- Ciclo de vida: `months_since_first` (meses desde primer pedido).\n",
        "- Priors de segmento (históricos, con **lag**): `region_digital_ratio_lag1`, `tipo_digital_ratio_lag1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Agregados cliente-mes\n",
        "monthly_agg = (df.groupBy(\"cliente_id\",\"month_first\",\"ym\")\n",
        "    .agg(\n",
        "        F.count(\"*\").alias(\"n_orders\"),\n",
        "        F.avg(\"is_digital\").alias(\"digital_ratio\"),\n",
        "        F.sum(F.col(\"facturacion_usd_val\").cast(\"double\")).alias(\"sum_fact\"),\n",
        "        F.avg(F.col(\"facturacion_usd_val\").cast(\"double\")).alias(\"avg_fact\"),\n",
        "        F.sum(F.col(\"cajas_fisicas\").cast(\"double\")).alias(\"sum_cajas\"),\n",
        "        F.avg(F.col(\"cajas_fisicas\").cast(\"double\")).alias(\"avg_cajas\"),\n",
        "        F.avg(F.col(\"materiales_distintos_val\").cast(\"double\")).alias(\"avg_mat_dist\"),\n",
        "        F.first(\"tipo_cliente_cd\", ignorenulls=True).alias(\"tipo_cliente_cd\"),\n",
        "        F.first(\"madurez_digital_cd\", ignorenulls=True).alias(\"madurez_digital_cd\"),\n",
        "        F.first(\"frecuencia_visitas_cd\", ignorenulls=True).alias(\"frecuencia_visitas_cd\"),\n",
        "        F.first(\"pais_cd\", ignorenulls=True).alias(\"pais_cd\"),\n",
        "        F.first(\"region_comercial_txt\", ignorenulls=True).alias(\"region_comercial_txt\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# Ciclo de vida\n",
        "w_client_month = Window.partitionBy(\"cliente_id\").orderBy(F.col(\"month_first\").asc())\n",
        "first_month = (monthly_agg\n",
        "               .withColumn(\"first_month\", F.first(\"month_first\", ignorenulls=True).over(w_client_month))\n",
        "               .select(\"cliente_id\",\"first_month\").distinct())\n",
        "monthly_agg = (monthly_agg\n",
        "               .join(first_month, on=\"cliente_id\", how=\"left\")\n",
        "               .withColumn(\"months_since_first\", F.floor(F.months_between(\"month_first\", \"first_month\"))))\n",
        "\n",
        "# Ratios por segmento + lag\n",
        "region_month = (df.groupBy(\"region_comercial_txt\",\"month_first\")\n",
        "                  .agg(F.avg(\"is_digital\").alias(\"region_digital_ratio\")))\n",
        "region_month = region_month.withColumn(\"ym\", F.date_format(\"month_first\", \"yyyy-MM\"))\n",
        "w_region = Window.partitionBy(\"region_comercial_txt\").orderBy(F.col(\"month_first\").asc())\n",
        "region_month = (region_month\n",
        "                .withColumn(\"region_digital_ratio_lag1\", F.lag(\"region_digital_ratio\", 1).over(w_region))\n",
        "                .select(\"region_comercial_txt\",\"ym\",\"region_digital_ratio_lag1\"))\n",
        "\n",
        "tipo_month = (df.groupBy(\"tipo_cliente_cd\",\"month_first\")\n",
        "                .agg(F.avg(\"is_digital\").alias(\"tipo_digital_ratio\")))\n",
        "tipo_month = tipo_month.withColumn(\"ym\", F.date_format(\"month_first\", \"yyyy-MM\"))\n",
        "w_tipo = Window.partitionBy(\"tipo_cliente_cd\").orderBy(F.col(\"month_first\").asc())\n",
        "tipo_month = (tipo_month\n",
        "              .withColumn(\"tipo_digital_ratio_lag1\", F.lag(\"tipo_digital_ratio\", 1).over(w_tipo))\n",
        "              .select(\"tipo_cliente_cd\",\"ym\",\"tipo_digital_ratio_lag1\"))\n",
        "\n",
        "# Dataset final\n",
        "w_roll3 = w_client_month.rowsBetween(-3, -1)  # 3 meses previos\n",
        "ds = (monthly_agg\n",
        "    .join(last_in_month, on=[\"cliente_id\",\"month_first\",\"ym\"], how=\"left\")\n",
        "    .withColumn(\"lag1_digital_ratio\", F.lag(\"digital_ratio\", 1).over(w_client_month))\n",
        "    .withColumn(\"n_orders_3m\", F.sum(\"n_orders\").over(w_roll3))\n",
        "    .withColumn(\"digital_ratio_3m\", F.avg(\"digital_ratio\").over(w_roll3))\n",
        "    .withColumn(\"sum_fact_3m\", F.sum(\"sum_fact\").over(w_roll3))\n",
        "    .withColumn(\"growth_digital_ratio\", F.col(\"digital_ratio\") - F.col(\"lag1_digital_ratio\"))\n",
        "    .join(region_month, on=[\"region_comercial_txt\",\"ym\"], how=\"left\")\n",
        "    .join(tipo_month, on=[\"tipo_cliente_cd\",\"ym\"], how=\"left\")\n",
        "    .filter(F.col(\"label\").isNotNull())\n",
        ")\n",
        "\n",
        "ds.select(\"cliente_id\",\"ym\",\"n_orders\",\"digital_ratio\",\"lag1_digital_ratio\",\n",
        "          \"n_orders_3m\",\"digital_ratio_3m\",\"growth_digital_ratio\",\n",
        "          \"months_since_first\",\"region_digital_ratio_lag1\",\"tipo_digital_ratio_lag1\",\n",
        "          \"label\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Split temporal y **balance de clases**\n",
        "\n",
        "- Train: `ym < TEST_START_YM`.  \n",
        "- Test:  `ym >= TEST_START_YM`.\n",
        "- Mostramos la **distribución de la etiqueta**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "train = ds.filter(F.col(\"ym\") < F.lit(TEST_START_YM))\n",
        "test  = ds.filter(F.col(\"ym\") >= F.lit(TEST_START_YM))\n",
        "\n",
        "print(\"Train rows:\", train.count(), \" | Test rows:\", test.count())\n",
        "print(\"\\nDistribución de la etiqueta:\")\n",
        "for name, d in [(\"train\", train), (\"test\", test)]:\n",
        "    print(f\"--- {name} ---\")\n",
        "    d.groupBy(\"label\").count().orderBy(\"label\").show()\n",
        "\n",
        "# Cachear para acelerar tuning\n",
        "train = train.repartition(200).persist(StorageLevel.MEMORY_AND_DISK)\n",
        "_ = train.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Pipelines de modelado (LR vs Árboles)\n",
        "\n",
        "- **LR**: imputación + *One-Hot* solo para **baja cardinalidad**.\n",
        "- **RF/GBT**: imputación + **solo indexación** (sin OHE) + `VectorIndexer` (reduce bins); usamos **priors** para `region_comercial_txt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Columnas numéricas base\n",
        "num_cols = [\"n_orders\",\"digital_ratio\",\"lag1_digital_ratio\",\"sum_fact\",\"avg_fact\",\n",
        "            \"sum_cajas\",\"avg_cajas\",\"avg_mat_dist\",\"recency_days_last\",\n",
        "            \"n_orders_3m\",\"digital_ratio_3m\",\"sum_fact_3m\",\"growth_digital_ratio\",\n",
        "            \"months_since_first\",\"region_digital_ratio_lag1\",\"tipo_digital_ratio_lag1\"]\n",
        "\n",
        "# Categóricas de baja cardinalidad (ajusta según tu data real)\n",
        "cat_low  = [\"madurez_digital_cd\",\"frecuencia_visitas_cd\",\"pais_cd\"]\n",
        "# `tipo_cliente_cd` suele ser manejable; si fuera muy alta, quítala de LR también\n",
        "cat_lr   = cat_low + [\"tipo_cliente_cd\"]\n",
        "\n",
        "# Para árboles evitamos OHE\n",
        "cat_tree = cat_low + [\"tipo_cliente_cd\"]\n",
        "\n",
        "# Imputación común\n",
        "imputer = Imputer(inputCols=num_cols, outputCols=[c + \"_imp\" for c in num_cols])\n",
        "\n",
        "# --- Pipeline base para LR ---\n",
        "idx_lr = [StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"keep\") for c in cat_lr]\n",
        "ohe_lr = OneHotEncoder(inputCols=[c + \"_idx\" for c in cat_lr],\n",
        "                       outputCols=[c + \"_oh\"  for c in cat_lr])\n",
        "feats_lr = [c + \"_imp\" for c in num_cols] + [c + \"_oh\" for c in cat_lr]\n",
        "asm_lr   = VectorAssembler(inputCols=feats_lr, outputCol=\"features_lr\")\n",
        "pipe_lr_base = Pipeline(stages=[imputer] + idx_lr + [ohe_lr, asm_lr])\n",
        "\n",
        "# --- Pipeline base para Árboles (sin OHE) ---\n",
        "idx_tree = [StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"keep\") for c in cat_tree]\n",
        "feats_tree = [c + \"_imp\" for c in num_cols] + [c + \"_idx\" for c in cat_tree]\n",
        "asm_tree   = VectorAssembler(inputCols=feats_tree, outputCol=\"features_raw\")\n",
        "vindex     = VectorIndexer(inputCol=\"features_raw\", outputCol=\"features\", maxCategories=64, handleInvalid=\"keep\")\n",
        "pipe_tree_base = Pipeline(stages=[imputer] + idx_tree + [asm_tree, vindex])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Constructores + grids compactos y **balanceo**\n",
        "\n",
        "Usamos `TrainValidationSplit` con grids moderados para evitar OOM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "e_pr = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
        "\n",
        "# Modelos\n",
        "lr = LogisticRegression(featuresCol=\"features_lr\", labelCol=\"label\",\n",
        "                        weightCol=\"weight\", maxIter=80, regParam=0.01, elasticNetParam=0.0)\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", weightCol=\"weight\",\n",
        "                            numTrees=100, maxDepth=8, maxBins=64,\n",
        "                            subsamplingRate=0.7, featureSubsetStrategy=\"auto\",\n",
        "                            cacheNodeIds=True, seed=42)\n",
        "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\",\n",
        "                    maxIter=80, maxDepth=6, maxBins=64,\n",
        "                    stepSize=0.05, subsamplingRate=0.7, seed=42)\n",
        "\n",
        "# Pipelines completos\n",
        "pipe_lr  = Pipeline(stages=pipe_lr_base.getStages() + [lr])\n",
        "pipe_rf  = Pipeline(stages=pipe_tree_base.getStages() + [rf])\n",
        "pipe_gbt = Pipeline(stages=pipe_tree_base.getStages() + [gbt])\n",
        "\n",
        "# Grids\n",
        "grid_lr  = (ParamGridBuilder()\n",
        "            .addGrid(lr.regParam, [0.0, 0.01, 0.1])\n",
        "            .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "            .build())\n",
        "grid_rf  = (ParamGridBuilder()\n",
        "            .addGrid(rf.numTrees, [80, 120])\n",
        "            .addGrid(rf.maxDepth, [6, 8])\n",
        "            .build())\n",
        "grid_gbt = (ParamGridBuilder()\n",
        "            .addGrid(gbt.maxIter, [60, 80])\n",
        "            .addGrid(gbt.maxDepth, [5, 6])\n",
        "            .build())\n",
        "\n",
        "tvs_lr  = TrainValidationSplit(estimator=pipe_lr,  estimatorParamMaps=grid_lr,  evaluator=e_pr, trainRatio=0.8, parallelism=1)\n",
        "tvs_rf  = TrainValidationSplit(estimator=pipe_rf,  estimatorParamMaps=grid_rf,  evaluator=e_pr, trainRatio=0.8, parallelism=1)\n",
        "tvs_gbt = TrainValidationSplit(estimator=pipe_gbt, estimatorParamMaps=grid_gbt, evaluator=e_pr, trainRatio=0.8, parallelism=1)\n",
        "\n",
        "def fit_model(name: str, train_df) -> Tuple:\n",
        "    # balanceo simple (positivos con weight > 1 si desbalance)\n",
        "    pos = train_df.filter(F.col(\"label\")==1).count()\n",
        "    neg = train_df.filter(F.col(\"label\")==0).count()\n",
        "    ratio = (neg / float(max(pos,1))) if pos else 1.0\n",
        "    train_w = train_df.withColumn(\"weight\", F.when(F.col(\"label\")==1, F.lit(ratio)).otherwise(F.lit(1.0)))\n",
        "\n",
        "    if name == \"lr\":\n",
        "        return tvs_lr.fit(train_w)\n",
        "    elif name == \"rf\":\n",
        "        return tvs_rf.fit(train_w)\n",
        "    elif name == \"gbt\":\n",
        "        # Nota: en algunas versiones GBT no soporta weightCol; usamos dataset sin weight\n",
        "        return tvs_gbt.fit(train_df)\n",
        "    else:\n",
        "        raise ValueError(\"Modelo no soportado: \" + name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Evaluación: AUC ROC / PR + matriz de confusión y métricas derivadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_df, model_name=\"model\"):\n",
        "    pred = model.transform(test_df).withColumn(\"p_digital\", vector_to_array(\"probability\")[1]).cache()\n",
        "    e_auc  = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "    e_aupr = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
        "    auc = e_auc.evaluate(pred)\n",
        "    aupr = e_aupr.evaluate(pred)\n",
        "\n",
        "    cm = (pred.groupBy(\"label\",\"prediction\").count().toPandas())\n",
        "    tp = int(cm[(cm[\"label\"]==1) & (cm[\"prediction\"]==1)][\"count\"].sum())\n",
        "    tn = int(cm[(cm[\"label\"]==0) & (cm[\"prediction\"]==0)][\"count\"].sum())\n",
        "    fp = int(cm[(cm[\"label\"]==0) & (cm[\"prediction\"]==1)][\"count\"].sum())\n",
        "    fn = int(cm[(cm[\"label\"]==1) & (cm[\"prediction\"]==0)][\"count\"].sum())\n",
        "\n",
        "    accuracy  = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
        "    precision = tp / max(tp + fp, 1)\n",
        "    recall    = tp / max(tp + fn, 1)\n",
        "    f1        = (2 * precision * recall) / max(precision + recall, 1e-9)\n",
        "\n",
        "    print(f\"[{model_name}]  AUC ROC: {auc:.4f} | AUC PR: {aupr:.4f} | Acc: {accuracy:.4f} | Prec: {precision:.4f} | Rec: {recall:.4f} | F1: {f1:.4f}\")\n",
        "    return pred, {\"auc_roc\": auc, \"auc_pr\": aupr, \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Entrenamiento y comparación (LR, RF, GBT)\n",
        "Seleccionamos el **mejor** por **AUC PR** (prioriza casos positivos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "results = {}\n",
        "models  = {}\n",
        "for name in [\"lr\",\"rf\",\"gbt\"]:\n",
        "    print(\"Entrenando modelo:\", name)\n",
        "    m = fit_model(name, train)\n",
        "    pred, mtx = evaluate_model(m, test, model_name=name)\n",
        "    results[name] = mtx\n",
        "    models[name]  = m\n",
        "\n",
        "print(\"\\nResumen (AUC PR):\", {k: round(v[\"auc_pr\"],4) for k,v in results.items()})\n",
        "best_name = max(results.items(), key=lambda kv: kv[1][\"auc_pr\"])[0]\n",
        "print(\"Mejor por AUC PR:\", best_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Ensemble ligero (promedio de probabilidades)\n",
        "\n",
        "Tip: combinar `LR` + `GBT` suele mejorar AUC PR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if \"lr\" in models and \"gbt\" in models:\n",
        "    pred_lr  = models[\"lr\"].transform(test).select(\"cliente_id\",\"ym\",\"label\", F.element_at(\"probability\",2).alias(\"p_lr\"))\n",
        "    pred_gbt = models[\"gbt\"].transform(test).select(\"cliente_id\",\"ym\", F.element_at(\"probability\",2).alias(\"p_gbt\"))\n",
        "    pred_ens = (pred_lr.join(pred_gbt, [\"cliente_id\",\"ym\"])\n",
        "                .withColumn(\"p_digital\", (F.col(\"p_lr\")+F.col(\"p_gbt\"))/2))\n",
        "    # Umbral 0.5 de referencia\n",
        "    pred_ens = pred_ens.withColumn(\"prediction\", F.when(F.col(\"p_digital\")>=0.5, F.lit(1.0)).otherwise(F.lit(0.0)))                        .withColumn(\"rawPrediction\", F.array(F.lit(1.0)-F.col(\"p_digital\"), F.col(\"p_digital\")))\n",
        "\n",
        "    e_auc  = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "    e_aupr = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
        "    auc = e_auc.evaluate(pred_ens)\n",
        "    aupr = e_aupr.evaluate(pred_ens)\n",
        "\n",
        "    cm = (pred_ens.groupBy(\"label\",\"prediction\").count().toPandas())\n",
        "    tp = int(cm[(cm[\"label\"]==1) & (cm[\"prediction\"]==1)][\"count\"].sum())\n",
        "    tn = int(cm[(cm[\"label\"]==0) & (cm[\"prediction\"]==0)][\"count\"].sum())\n",
        "    fp = int(cm[(cm[\"label\"]==0) & (cm[\"prediction\"]==1)][\"count\"].sum())\n",
        "    fn = int(cm[(cm[\"label\"]==1) & (cm[\"prediction\"]==0)][\"count\"].sum())\n",
        "\n",
        "    accuracy  = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
        "    precision = tp / max(tp + fp, 1)\n",
        "    recall    = tp / max(tp + fn, 1)\n",
        "    f1        = (2 * precision * recall) / max(precision + recall, 1e-9)\n",
        "\n",
        "    print(f\"[Ensemble LR+GBT]  AUC ROC: {auc:.4f} | AUC PR: {aupr:.4f} | Acc: {accuracy:.4f} | Prec: {precision:.4f} | Rec: {recall:.4f} | F1: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) (Opcional) Backtesting por cortes temporales\n",
        "\n",
        "Repite entrenamiento (grids compactos) para cada `ym` en `BACKTEST_SPLITS` y reporta AUC PR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "bt_rows = []\n",
        "for cut in BACKTEST_SPLITS:\n",
        "    train_bt = ds.filter(F.col(\"ym\") < F.lit(cut)).repartition(200).persist(StorageLevel.MEMORY_AND_DISK)\n",
        "    test_bt  = ds.filter(F.col(\"ym\") >= F.lit(cut))\n",
        "    print(f\"\\n>>> Backtest corte {cut} | train={train_bt.count()} test={test_bt.count()}\")\n",
        "\n",
        "    metrics_cut = {}\n",
        "    for name in [\"lr\",\"gbt\"]:  # rf opcional si hay suficiente memoria/tiempo\n",
        "        print(\"  Entrenando:\", name)\n",
        "        m = fit_model(name, train_bt)\n",
        "        _, mtx = evaluate_model(m, test_bt, model_name=name)\n",
        "        metrics_cut[name] = mtx[\"auc_pr\"]\n",
        "    bt_rows.append((cut, metrics_cut.get(\"lr\"), metrics_cut.get(\"gbt\")))\n",
        "\n",
        "print(\"\\nAUC PR por corte (LR, GBT):\")\n",
        "for cut, lr_auc, gbt_auc in bt_rows:\n",
        "    print(cut, \" | LR:\", round(lr_auc or 0, 4), \" | GBT:\", round(gbt_auc or 0, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) (Opcional) Guardado de artefactos\n",
        "\n",
        "Descomenta para guardar el mejor modelo y las predicciones del test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "# base_path = Path(\"artifacts\")\n",
        "# base_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# # Guardar mejor modelo por AUC PR\n",
        "# best_model = models[best_name]\n",
        "# best_model.bestModel.write().overwrite().save(str(base_path / f\"best_pipeline_{best_name}\"))\n",
        "\n",
        "# # Guardar predicciones del mejor\n",
        "# pred_best = best_model.transform(test).withColumn(\"p_digital\", vector_to_array(\"probability\")[1])\n",
        "# pred_best.select(\"cliente_id\",\"ym\",\"label\",\"p_digital\",\"prediction\").write.mode(\"overwrite\").parquet(str(base_path / \"predicciones_best\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Notas\n",
        "- Evitamos **OutOfMemory** en árboles al **no usar One-Hot** y limitar `maxDepth`, `numTrees` y `maxBins`.\n",
        "- Usamos **priors lagged** por segmento para mantener señal de `region_comercial_txt` sin inflar dimensionalidad.\n",
        "- Para más velocidad, puedes reducir aún más el grid o usar `TrainValidationSplit.trainRatio=0.9`."
      ]
    }
  ]
}